# 19271169-张东植-实验报告4

[TOC]

- **Gitlab repo: http://202.205.102.126:88/ZhangDongZhi/os-lab.git**



​	The main purpose of this experiment is to implement an operating system that supports multi-program and cooperative scheduling. Through this experiment, we can realize an operating system that supports multi-program and cooperative scheduling. It includes application program placement, multi-channel program loading, task design and implementation, system call like sys_yield and sys_exit implementation, etc.

# 1. 实现应用程序

​	The application implementation of multiprogram operating system is basically the same as that of batch operating system. The main difference is where the application is loaded into memory. At the same time, in a multiprogram operating system, an application can voluntarily give up the CPU to switch to another application. Collaborative scheduling means that the application program actively cedes the CPU during THE I/O operation so that the CPU can execute other applications and ultimately improve the CPU efficiency.

## 1.1 Settings

​	In a batch operating system, the memory location for application loading is the same. However, in a multiprogram operating system, each application loads at a different location. This is why the BASE_ADDRESS of "**linker.ld**" in the linker script is different. To do this, we need to write a script called "**build.py**" that implements custom link scripts for each application.

```rust
// user/build.py
import os

base_address = 0x80400000
step = 0x20000
linker = 'src/linker.ld'

app_id = 0
apps = os.listdir('src/bin')
apps.sort()
for app in apps:
    app = app[:app.find('.')]
    lines = []
    lines_before = []
    with open(linker, 'r') as f:
        for line in f.readlines():
            lines_before.append(line)
            line = line.replace(hex(base_address), hex(base_address+step*app_id))
            lines.append(line)
    with open(linker, 'w+') as f:
        f.writelines(lines)
    os.system('cargo build --bin %s --release' % app)
    print('[build.py] application %s start with address %s' %(app, hex(base_address+step*app_id)))
    with open(linker, 'w+') as f:
        f.writelines(lines_before)
    app_id = app_id + 1
```

![image-20211112161002489](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161002489.png)

## 1.2 Yield

​	The procedures performed by the application are usually computations and IO intermittently executed. If the program still occupies CPU during the IO execution, it will cause a waste of CPU resources. Multiprogramming allows applications to actively cede CPU privileges to other applications while performing IO operations. Yield system calls are system calls that enable an application to voluntarily surrender CPU privileges.

```rust
// sys_yield
const SYSCALL_YIELD: usize = 124;

pub fn sys_yield() -> isize {
    syscall(SYSCALL_YIELD, [0, 0, 0])
}

// lib.rs
pub fn yield_() -> isize { sys_yield() }
```

![image-20211112161133282](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161133282.png)

![image-20211112161215454](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161215454.png)

## 1.3 Test

​	Then, we can now execute the make build command in the user directory to compile the multiprogram operating system application.

- **00write_a.rs :** 

  ![image-20211112161327291](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161327291.png)

- **01write_b.rs :** 

  ![image-20211112161340309](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161340309.png)

- **02write_c.rs :** 

  ![image-20211112161354015](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161354015.png)

- **make build ：**

  ![image-20211113141450926](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211113141450926.png)



# 2. 多道程序加载

​	In batch operating systems, the loading and execution of applications is handled by the **batch** submodule. In a multiprogram operating system, the loading and execution of application programs are divided into two modules. The **loader** submodule is responsible for loading applications, and the **task** submodule is responsible for executing and switching applications. Also, unlike batch operating systems, the applications used by multiprogram operating systems are loaded together into memory when the kernel is initialized.

1. First, separate some constants into **"config.rs"**.

   ```rust
   pub const USER_STACK_SIZE: usize = 4096 * 2;
   pub const KERNEL_STACK_SIZE: usize = 4096 * 2;
   pub const MAX_APP_NUM: usize = 4;
   pub const APP_BASE_ADDRESS: usize = 0x80400000;
   pub const APP_SIZE_LIMIT: usize = 0x20000;
   ```

   ![image-20211112163444590](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112163444590.png)

2. Reuse batch submodule kernel stack and user stack code. Note that the kernel stack context information has been added to the task context information.

   ```rust
   use crate::trap::TrapContext;
   use crate::task::TaskContext;
   use crate::config::*;
   
   #[repr(align(4096))]
   #[derive(Copy, Clone)]
   struct KernelStack {
       data: [u8; KERNEL_STACK_SIZE],
   }
   
   #[repr(align(4096))]
   #[derive(Copy, Clone)]
   struct UserStack {
       data: [u8; USER_STACK_SIZE],
   }
   
   static KERNEL_STACK: [KernelStack; MAX_APP_NUM] = [
       KernelStack { data: [0; KERNEL_STACK_SIZE], };
       MAX_APP_NUM
   ];
   
   static USER_STACK: [UserStack; MAX_APP_NUM] = [
       UserStack { data: [0; USER_STACK_SIZE], };
       MAX_APP_NUM
   ];
   
   impl KernelStack {
       fn get_sp(&self) -> usize {
           self.data.as_ptr() as usize + KERNEL_STACK_SIZE
       }
       pub fn push_context(&self, trap_cx: TrapContext, task_cx: TaskContext) -> &'static mut TaskContext {
           unsafe {
               let trap_cx_ptr = (self.get_sp() - core::mem::size_of::<TrapContext>()) as *mut TrapContext;
               *trap_cx_ptr = trap_cx;
               let task_cx_ptr = (trap_cx_ptr as usize - core::mem::size_of::<TaskContext>()) as *mut TaskContext;
               *task_cx_ptr = task_cx;
               task_cx_ptr.as_mut().unwrap()
           }
       }
   }
   
   impl UserStack {
       fn get_sp(&self) -> usize {
           self.data.as_ptr() as usize + USER_STACK_SIZE
       }
   }
   ```

3. **Load the program.**

   ```rust
   fn get_base_i(app_id: usize) -> usize {
       APP_BASE_ADDRESS + app_id * APP_SIZE_LIMIT
   }
   
   pub fn get_num_app() -> usize {
       extern "C" { fn _num_app(); }
       unsafe { (_num_app as usize as *const usize).read_volatile() }
   }
   
   pub fn load_apps() {
       extern "C" { fn _num_app(); }
       let num_app_ptr = _num_app as usize as *const usize;
       let num_app = get_num_app();
       let app_start = unsafe {
           core::slice::from_raw_parts(num_app_ptr.add(1), num_app + 1)
       };
       // clear i-cache first
       unsafe { asm!("fence.i"); }
       // load apps
       for i in 0..num_app {
           let base_i = get_base_i(i);
           // clear region
           (base_i..base_i + APP_SIZE_LIMIT).for_each(|addr| unsafe {
               (addr as *mut u8).write_volatile(0)
           });
           // load app from data section to memory
           let src = unsafe {
               core::slice::from_raw_parts(app_start[i] as *const u8, app_start[i + 1] - app_start[i])
           };
           let dst = unsafe {
               core::slice::from_raw_parts_mut(base_i as *mut u8, src.len())
           };
           dst.copy_from_slice(src);
       }
   }
   ```

   ![image-20211112163607853](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112163607853.png)

   We can see that the application is loaded at the physical address calculated by **get_base_i**.



# 3. 任务设计与实现

​	Multiprogramming enables applications to voluntarily surrender CPU usage. We call a computational execution a task. Switching a task from one application to another is called task switching. The contents such as registers and stacks that need to be saved during the task switchover are called task lead-in files. Different from Trap switching, task switching does not involve privilege switching.

## 3.1 Context Switch

​	Task switching needs to be supported by task context. We use the **TaskContext** data structure to record the context information of the task.

```rust
#[repr(C)]
pub struct TaskContext {
    ra: usize,
    s: [usize; 12],
}

impl TaskContext {
    pub fn goto_restore() -> Self {
        extern "C" { fn __restore(); }
        Self {
            ra: __restore as usize,
            s: [0; 12],
        }
    }
}
```

![image-20211112163833166](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112163833166.png)

## 3.2 Task condition & TCB

​	To support task switching, we need to maintain the running state of the task in the kernel. The kernel also needs to store more information in the task control block. A task context address pointer task_cx_ptr is maintained in the task control block.

```rust
#[derive(Copy, Clone, PartialEq)]
pub enum TaskStatus {
    UnInit,
    Ready,
    Running,
    Exited,
}

#[derive(Copy, Clone)]
pub struct TaskControlBlock {
    pub task_cx_ptr: usize,
    pub task_status: TaskStatus,
}

impl TaskControlBlock {
    pub fn get_task_cx_ptr2(&self) -> *const usize {
        &self.task_cx_ptr as *const usize
    }
}
```

![image-20211112164059828](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112164059828.png)

## 3.3 Task Switch

​	The main process of task switching is that after saving the context of a task, the task enters the pause state. At the same time, restore the context of another task and let it continue on the CPU.

```rust
.altmacro
.macro SAVE_SN n
    sd s\n, (\n+1)*8(sp)
.endm
.macro LOAD_SN n
    ld s\n, (\n+1)*8(sp)
.endm
    .section .text
    .globl __switch
__switch:
    # __switch(
    #     current_task_cx_ptr2: &*const TaskContext,
    #     next_task_cx_ptr2: &*const TaskContext
    # )
    # push TaskContext to current sp and save its address to where a0 points to
    addi sp, sp, -13*8
    sd sp, 0(a0)
    # fill TaskContext with ra & s0-s11
    sd ra, 0(sp)
    .set n, 0
    .rept 12
        SAVE_SN %n
        .set n, n + 1
    .endr
    # ready for loading TaskContext a1 points to
    ld sp, 0(a1)
    # load registers in the TaskContext
    ld ra, 0(sp)
    .set n, 0
    .rept 12
        LOAD_SN %n
        .set n, n + 1
    .endr
    # pop TaskContext
    addi sp, sp, 13*8
    ret
```

![image-20211112164313624](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112164313624.png)

​	To make it easier to call **__switch**, you also need to wrap it as a function of Rust.

```rust
global_asm!(include_str!("switch.S"));

extern "C" {
    pub fn __switch(
        current_task_cx_ptr2: *const usize,
        next_task_cx_ptr2: *const usize
    );
}
```

![image-20211112164357047](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112164357047.png)

## 3.4 Task Manager

​	We need a global task manager to manage the application described by **task control**.

```rust
mod context;
mod switch;
mod task;

use crate::config::MAX_APP_NUM;
use crate::loader::{get_num_app, init_app_cx};
use core::cell::RefCell;
use lazy_static::*;
use switch::__switch;
use task::{TaskControlBlock, TaskStatus};

pub use context::TaskContext;

pub struct TaskManager {
    num_app: usize,
    inner: RefCell<TaskManagerInner>,
}

struct TaskManagerInner {
    tasks: [TaskControlBlock; MAX_APP_NUM],
    current_task: usize,
}

unsafe impl Sync for TaskManager {}

lazy_static! {
    pub static ref TASK_MANAGER: TaskManager = {
        let num_app = get_num_app();
        let mut tasks = [
            TaskControlBlock { task_cx_ptr: 0, task_status: TaskStatus::UnInit };
            MAX_APP_NUM
        ];
        for i in 0..num_app {
            tasks[i].task_cx_ptr = init_app_cx(i) as * const _ as usize;
            tasks[i].task_status = TaskStatus::Ready;
        }
        TaskManager {
            num_app,
            inner: RefCell::new(TaskManagerInner {
                tasks,
                current_task: 0,
            }),
        }
    };
}

impl TaskManager {
    fn run_first_task(&self) {
        self.inner.borrow_mut().tasks[0].task_status = TaskStatus::Running;
        let next_task_cx_ptr2 = self.inner.borrow().tasks[0].get_task_cx_ptr2();
        let _unused: usize = 0;
        unsafe {
            __switch(
                &_unused as *const _,
                next_task_cx_ptr2,
            );
        }
    }

    fn mark_current_suspended(&self) {
        let mut inner = self.inner.borrow_mut();
        let current = inner.current_task;
        inner.tasks[current].task_status = TaskStatus::Ready;
    }

    fn mark_current_exited(&self) {
        let mut inner = self.inner.borrow_mut();
        let current = inner.current_task;
        inner.tasks[current].task_status = TaskStatus::Exited;
    }

    fn find_next_task(&self) -> Option<usize> {
        let inner = self.inner.borrow();
        let current = inner.current_task;
        (current + 1..current + self.num_app + 1)
            .map(|id| id % self.num_app)
            .find(|id| {
                inner.tasks[*id].task_status == TaskStatus::Ready
            })
    }

    fn run_next_task(&self) {
        if let Some(next) = self.find_next_task() {
            let mut inner = self.inner.borrow_mut();
            let current = inner.current_task;
            inner.tasks[next].task_status = TaskStatus::Running;
            inner.current_task = next;
            let current_task_cx_ptr2 = inner.tasks[current].get_task_cx_ptr2();
            let next_task_cx_ptr2 = inner.tasks[next].get_task_cx_ptr2();
            core::mem::drop(inner);
            unsafe {
                __switch(
                    current_task_cx_ptr2,
                    next_task_cx_ptr2,
                );
            }
        } else {
            panic!("All applications completed!");
        }
    }
}

pub fn run_first_task() {
    TASK_MANAGER.run_first_task();
}

fn run_next_task() {
    TASK_MANAGER.run_next_task();
}

fn mark_current_suspended() {
    TASK_MANAGER.mark_current_suspended();
}

fn mark_current_exited() {
    TASK_MANAGER.mark_current_exited();
}

pub fn suspend_current_and_run_next() {
    mark_current_suspended();
    run_next_task();
}

pub fn exit_current_and_run_next() {
    mark_current_exited();
    run_next_task();
}
```

The above code also calls **init_app_cx** of the Loader submodule. Therefore, you also need to add code in "**loader.rs**".

```rust
// os/src/loader.rs

pub fn init_app_cx(app_id: usize) -> &'static TaskContext {
    KERNEL_STACK[app_id].push_context(
        TrapContext::app_init_context(get_base_i(app_id), USER_STACK[app_id].get_sp()),
        TaskContext::goto_restore(),
    )
}
```

![image-20211112164639461](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112164639461.png)

​	Analyzing this part of the code shows that KernelStack presses a Trap context and then a task context. The TaskContext is constructed by **TaskContext::goto_restore().**



# 4. sys_yield & sys_exit

​	To implement the two system calls, we need to modify file **"process.rs"** as below.

```rust
use crate::task::{
    suspend_current_and_run_next,
    exit_current_and_run_next,
};

pub fn sys_exit(exit_code: i32) -> ! {
    println!("[kernel] Application exited with code {}", exit_code);
    exit_current_and_run_next();
    panic!("Unreachable in sys_exit!");
}

pub fn sys_yield() -> isize {
    suspend_current_and_run_next();
    0
}
```

![image-20211112161931624](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161931624.png)

​	Besides, we need  to change to **"mod.rs"** to add sys_yield to the handling of system calls. Both system calls are implemented based on the interface provided by the Task submodule. We need to add some codes to it.

```rust
const SYSCALL_YIELD: usize = 124;

SYSCALL_YIELD => sys_yield(),
```

![image-20211112162035056](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112162035056.png)



# 5. 完善程序

​	We need to comment out the run_next_app() part of the trap submodule. Also, comment out mv sp, a0 in __restore in trap.S. Then, file "main.rs" is as below.

![image-20211112161745245](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211112161745245.png)



# 6. 运行结果

![image-20211113141655863](C:\Users\Dal-Z41\AppData\Roaming\Typora\typora-user-images\image-20211113141655863.png)